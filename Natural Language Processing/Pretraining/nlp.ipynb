{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b45b0372",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c094ab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc4581a",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2571f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# sentences: 42069'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_ptb():\n",
    "    \"\"\"Load the PTB dataset into a list of text lines.\"\"\"\n",
    "    data_dir = 'ptb/'\n",
    "    # Read the training set\n",
    "    with open(os.path.join(data_dir, 'ptb.train.txt')) as f:\n",
    "        raw_text = f.read()\n",
    "    return [line.split() for line in raw_text.split('\\n')]\n",
    "\n",
    "sentences = read_ptb()\n",
    "f'# sentences: {len(sentences)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9ccc960",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    \"\"\"Vocabulary for text.\"\"\"\n",
    "    def __init__(self, tokens=[], min_freq=0, reserved_tokens=[]):\n",
    "        \"\"\"Defined in :numref:`sec_text-sequence`\"\"\"\n",
    "        # Flatten a 2D list if needed\n",
    "        if tokens and isinstance(tokens[0], list):\n",
    "            tokens = [token for line in tokens for token in line]\n",
    "        # Count token frequencies\n",
    "        counter = collections.Counter(tokens)\n",
    "        self.token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                  reverse=True)\n",
    "        # The list of unique tokens\n",
    "        self.idx_to_token = list(sorted(set(['<unk>'] + reserved_tokens + [\n",
    "            token for token, freq in self.token_freqs if freq >= min_freq])))\n",
    "        self.token_to_idx = {token: idx\n",
    "                             for idx, token in enumerate(self.idx_to_token)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if hasattr(indices, '__len__') and len(indices) > 1:\n",
    "            return [self.idx_to_token[int(index)] for index in indices]\n",
    "        return self.idx_to_token[indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):  # Index for the unknown token\n",
    "        return self.token_to_idx['<unk>']\n",
    "    \n",
    "def tokenize(text):\n",
    "    return list(text)\n",
    "\n",
    "def build(raw_text, vocab=None):\n",
    "    tokens = tokenize(preprocess(raw_text))\n",
    "    if vocab is None: vocab = Vocab(tokens)\n",
    "    corpus = [vocab[token] for token in tokens]\n",
    "    return corpus, vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c53d66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vocab size: 6719'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = Vocab(sentences, min_freq=10)\n",
    "f'vocab size: {len(vocab)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cc3542",
   "metadata": {},
   "source": [
    "## Subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bf313e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample(sentences, vocab):\n",
    "    \"\"\"Subsample high-frequency words.\"\"\"\n",
    "    # Exclude unknown tokens ('<unk>')\n",
    "    sentences = [[token for token in line if vocab[token] != vocab.unk]\n",
    "                 for line in sentences]\n",
    "    counter = collections.Counter([\n",
    "        token for line in sentences for token in line])\n",
    "    num_tokens = sum(counter.values())\n",
    "\n",
    "    # Return True if `token` is kept during subsampling\n",
    "    def keep(token):\n",
    "        return(random.uniform(0, 1) <\n",
    "               math.sqrt(1e-4 / counter[token] * num_tokens))\n",
    "\n",
    "    return ([[token for token in line if keep(token)] for line in sentences],\n",
    "            counter)\n",
    "\n",
    "subsampled, counter = subsample(sentences, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed97728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_list_len_pair_hist(legend, xlabel, ylabel, xlist, ylist):\n",
    "    \"\"\"Plot the histogram for list length pairs.\n",
    "\n",
    "    Defined in :numref:`sec_machine_translation`\"\"\"\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    _, _, patches = plt.hist(\n",
    "        [[len(l) for l in xlist], [len(l) for l in ylist]])\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    for patch in patches[1].patches:\n",
    "        patch.set_hatch('/')\n",
    "    plt.legend(legend)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22fa9d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_list_len_pair_hist(['origin', 'subsampled'], '# tokens per sentence',\n",
    "                            'count', sentences, subsampled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e68ecca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# of \"the\": before=50770, after=2120'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_counts(token):\n",
    "    return (f'# of \"{token}\": '\n",
    "            f'before={sum([l.count(token) for l in sentences])}, '\n",
    "            f'after={sum([l.count(token) for l in subsampled])}')\n",
    "\n",
    "compare_counts('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "596f3008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# of \"join\": before=45, after=45'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_counts('join')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2a32ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [4127, 6612, 3228], [3922, 1922, 4743]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [vocab[line] for line in subsampled]\n",
    "corpus[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e6e913",
   "metadata": {},
   "source": [
    "## Center and Context Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5608cd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centers_and_contexts(corpus, max_window_size):\n",
    "    \"\"\"Return center words and context words in skip-gram.\"\"\"\n",
    "    centers, contexts = [], []\n",
    "    for line in corpus:\n",
    "        # To form a \"center word--context word\" pair, each sentence needs to\n",
    "        # have at least 2 words\n",
    "        if len(line) < 2:\n",
    "            continue\n",
    "        centers += line\n",
    "        for i in range(len(line)):  # Context window centered at `i`\n",
    "            window_size = random.randint(1, max_window_size)\n",
    "            indices = list(range(max(0, i - window_size),\n",
    "                                 min(len(line), i + 1 + window_size)))\n",
    "            # Exclude the center word from the context words\n",
    "            indices.remove(i)\n",
    "            contexts.append([line[idx] for idx in indices])\n",
    "    return centers, contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7300579e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset [[0, 1, 2, 3, 4, 5, 6], [7, 8, 9]]\n",
      "center 0 has contexts [1, 2]\n",
      "center 1 has contexts [0, 2, 3]\n",
      "center 2 has contexts [1, 3]\n",
      "center 3 has contexts [2, 4]\n",
      "center 4 has contexts [2, 3, 5, 6]\n",
      "center 5 has contexts [3, 4, 6]\n",
      "center 6 has contexts [4, 5]\n",
      "center 7 has contexts [8]\n",
      "center 8 has contexts [7, 9]\n",
      "center 9 has contexts [7, 8]\n"
     ]
    }
   ],
   "source": [
    "tiny_dataset = [list(range(7)), list(range(7, 10))]\n",
    "print('dataset', tiny_dataset)\n",
    "for center, context in zip(*get_centers_and_contexts(tiny_dataset, 2)):\n",
    "    print('center', center, 'has contexts', context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bd94fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# center-context pairs: 1500903'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_centers, all_contexts = get_centers_and_contexts(corpus, 5)\n",
    "f'# center-context pairs: {sum([len(contexts) for contexts in all_contexts])}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab451f60",
   "metadata": {},
   "source": [
    "## Negative Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "880a7afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomGenerator:\n",
    "    \"\"\"Randomly draw among {1, ..., n} according to n sampling weights.\"\"\"\n",
    "    def __init__(self, sampling_weights):\n",
    "        # Exclude\n",
    "        self.population = list(range(1, len(sampling_weights) + 1))\n",
    "        self.sampling_weights = sampling_weights\n",
    "        self.candidates = []\n",
    "        self.i = 0\n",
    "\n",
    "    def draw(self):\n",
    "        if self.i == len(self.candidates):\n",
    "            # Cache `k` random sampling results\n",
    "            self.candidates = random.choices(\n",
    "                self.population, self.sampling_weights, k=10000)\n",
    "            self.i = 0\n",
    "        self.i += 1\n",
    "        return self.candidates[self.i - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c0ad63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 2, 1, 2, 2, 3, 2, 3, 1]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = RandomGenerator([2, 3, 4])\n",
    "[generator.draw() for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c363cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_negatives(all_contexts, vocab, counter, K):\n",
    "    \"\"\"Return noise words in negative sampling.\"\"\"\n",
    "    # Sampling weights for words with indices 1, 2, ... (index 0 is the\n",
    "    # excluded unknown token) in the vocabulary\n",
    "    sampling_weights = [counter[vocab.to_tokens(i)]**0.75\n",
    "                        for i in range(1, len(vocab))]\n",
    "    all_negatives, generator = [], RandomGenerator(sampling_weights)\n",
    "    for contexts in all_contexts:\n",
    "        negatives = []\n",
    "        while len(negatives) < len(contexts) * K:\n",
    "            neg = generator.draw()\n",
    "            # Noise words cannot be context words\n",
    "            if neg not in contexts:\n",
    "                negatives.append(neg)\n",
    "        all_negatives.append(negatives)\n",
    "    return all_negatives\n",
    "\n",
    "all_negatives = get_negatives(all_contexts, vocab, counter, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ef9b23",
   "metadata": {},
   "source": [
    "## Loading in minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e66b77e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(data):\n",
    "    \"\"\"Return a minibatch of examples for skip-gram with negative sampling.\"\"\"\n",
    "    max_len = max(len(c) + len(n) for _, c, n in data)\n",
    "    centers, contexts_negatives, masks, labels = [], [], [], []\n",
    "    for center, context, negative in data:\n",
    "        cur_len = len(context) + len(negative)\n",
    "        centers += [center]\n",
    "        contexts_negatives += [context + negative + [0] * (max_len - cur_len)]\n",
    "        masks += [[1] * cur_len + [0] * (max_len - cur_len)]\n",
    "        labels += [[1] * len(context) + [0] * (max_len - len(context))]\n",
    "    return (torch.tensor(centers).reshape((-1, 1)), torch.tensor(\n",
    "        contexts_negatives), torch.tensor(masks), torch.tensor(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5071457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centers = tensor([[1],\n",
      "        [1]])\n",
      "contexts_negatives = tensor([[2, 2, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 3, 3, 0]])\n",
      "masks = tensor([[1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0]])\n",
      "labels = tensor([[1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x_1 = (1, [2, 2], [3, 3, 3, 3])\n",
    "x_2 = (1, [2, 2, 2], [3, 3])\n",
    "batch = batchify((x_1, x_2))\n",
    "\n",
    "names = ['centers', 'contexts_negatives', 'masks', 'labels']\n",
    "for name, data in zip(names, batch):\n",
    "    print(name, '=', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e3d6343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_ptb(batch_size, max_window_size, num_noise_words):\n",
    "    \"\"\"Download the PTB dataset and then load it into memory.\"\"\"\n",
    "    sentences = read_ptb()\n",
    "    vocab = Vocab(sentences, min_freq=10)\n",
    "    subsampled, counter = subsample(sentences, vocab)\n",
    "    corpus = [vocab[line] for line in subsampled]\n",
    "    all_centers, all_contexts = get_centers_and_contexts(\n",
    "        corpus, max_window_size)\n",
    "    all_negatives = get_negatives(\n",
    "        all_contexts, vocab, counter, num_noise_words)\n",
    "\n",
    "    class PTBDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, centers, contexts, negatives):\n",
    "            assert len(centers) == len(contexts) == len(negatives)\n",
    "            self.centers = centers\n",
    "            self.contexts = contexts\n",
    "            self.negatives = negatives\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            return (self.centers[index], self.contexts[index],\n",
    "                    self.negatives[index])\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.centers)\n",
    "\n",
    "    dataset = PTBDataset(all_centers, all_contexts, all_negatives)\n",
    "\n",
    "    data_iter = torch.utils.data.DataLoader(dataset, batch_size, shuffle=True,\n",
    "                                      collate_fn=batchify)\n",
    "    return data_iter, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51b11179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centers shape: torch.Size([512, 1])\n",
      "contexts_negatives shape: torch.Size([512, 60])\n",
      "masks shape: torch.Size([512, 60])\n",
      "labels shape: torch.Size([512, 60])\n"
     ]
    }
   ],
   "source": [
    "data_iter, vocab = load_data_ptb(512, 5, 5)\n",
    "for batch in data_iter:\n",
    "    for name, data in zip(names, batch):\n",
    "        print(name, 'shape:', data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c64f76b",
   "metadata": {},
   "source": [
    "# Pretraining Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2b65abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, max_window_size, num_noise_words = 512, 5, 5\n",
    "data_iter, vocab = load_data_ptb(batch_size, max_window_size,\n",
    "                                     num_noise_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54474f0",
   "metadata": {},
   "source": [
    "## The Skip-Gram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58930291",
   "metadata": {},
   "source": [
    "### Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5936bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter embedding_weight (torch.Size([20, 4]), dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "embed = nn.Embedding(num_embeddings=20, embedding_dim=4)\n",
    "print(f'Parameter embedding_weight ({embed.weight.shape}, '\n",
    "      f'dtype={embed.weight.dtype})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "192b83d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2121,  0.2808,  0.1648,  1.7570],\n",
       "         [-0.3538, -0.5664,  0.0772, -1.4539],\n",
       "         [ 1.7770,  0.7790,  0.0772, -1.1219]],\n",
       "\n",
       "        [[-0.2947,  0.6209, -1.7282, -0.5310],\n",
       "         [ 0.2633,  0.4284, -1.2538, -0.0367],\n",
       "         [-1.3455,  0.3515,  1.4637,  1.1351]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "embed(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce04cb4",
   "metadata": {},
   "source": [
    "### Defining Forward Propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5fdb8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_gram(center, contexts_and_negatives, embed_v, embed_u):\n",
    "    v = embed_v(center)\n",
    "    u = embed_u(contexts_and_negatives)\n",
    "    pred = torch.bmm(v, u.permute(0, 2, 1))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3abd0d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_gram(torch.ones((2, 1), dtype=torch.long),\n",
    "          torch.ones((2, 4), dtype=torch.long), embed, embed).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da66180",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e556ed29",
   "metadata": {},
   "source": [
    "### Binary Cross-Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f837c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidBCELoss(nn.Module):\n",
    "    # Binary cross-entropy loss with masking\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, inputs, target, mask=None):\n",
    "        out = nn.functional.binary_cross_entropy_with_logits(\n",
    "            inputs, target, weight=mask, reduction=\"none\")\n",
    "        return out.mean(dim=1)\n",
    "\n",
    "loss = SigmoidBCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3844fdcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9352, 1.8462])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.tensor([[1.1, -2.2, 3.3, -4.4]] * 2)\n",
    "label = torch.tensor([[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]])\n",
    "mask = torch.tensor([[1, 1, 1, 1], [1, 1, 0, 0]])\n",
    "loss(pred, label, mask) * mask.shape[1] / mask.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f644a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9352\n",
      "1.8462\n"
     ]
    }
   ],
   "source": [
    "def sigmd(x):\n",
    "    return -math.log(1 / (1 + math.exp(-x)))\n",
    "\n",
    "print(f'{(sigmd(1.1) + sigmd(2.2) + sigmd(-3.3) + sigmd(4.4)) / 4:.4f}')\n",
    "print(f'{(sigmd(-1.1) + sigmd(-2.2)) / 2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e38fce",
   "metadata": {},
   "source": [
    "### Initializing Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18d904de",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 100\n",
    "net = nn.Sequential(nn.Embedding(num_embeddings=len(vocab),\n",
    "                                 embedding_dim=embed_size),\n",
    "                    nn.Embedding(num_embeddings=len(vocab),\n",
    "                                 embedding_dim=embed_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b23eac1",
   "metadata": {},
   "source": [
    "### Defining the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac7a8410",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Animator:  # Define a new Animator class that properly handles None values\n",
    "\tdef __init__(self, xlabel=None, ylabel=None, legend=None):\n",
    "\t\tself.data = {'train_loss': [], 'train_acc': [], 'test_acc': []}\n",
    "\t\tself.epochs = []\n",
    "\t\t\n",
    "\tdef add(self, epoch, metrics):\n",
    "\t\tself.epochs.append(epoch)\n",
    "\t\ttrain_loss, train_acc, test_acc = metrics\n",
    "\t\tif train_loss is not None:\n",
    "\t\t\tself.data['train_loss'].append(float(train_loss))\n",
    "\t\tif train_acc is not None:\n",
    "\t\t\tself.data['train_acc'].append(float(train_acc))\n",
    "\t\tif test_acc is not None:\n",
    "\t\t\tself.data['test_acc'].append(float(test_acc))\n",
    "\t\t\t\n",
    "\tdef show(self):\n",
    "\t\tplt.figure(figsize=(10, 6))\n",
    "\t\tfor label, values in self.data.items():\n",
    "\t\t\tif values:  # Only plot if we have data\n",
    "\t\t\t\tplt.plot(self.epochs[:len(values)], values, label=label)\n",
    "\t\tplt.xlabel('Epoch')\n",
    "\t\tplt.ylabel('Metric Value')\n",
    "\t\tplt.legend()\n",
    "\t\tplt.grid(True)\n",
    "\t\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "888ce816",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accumulator:\n",
    "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
    "    def __init__(self, n):\n",
    "        \"\"\"Defined in :numref:`sec_softmax_scratch`\"\"\"\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "024ad4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    \"\"\"Recording multiple running times.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start the timer.\"\"\"\n",
    "        self.tik = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the timer and record the time in a list.\"\"\"\n",
    "        self.times.append(time.time() - self.tik)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self):\n",
    "        \"\"\"Return the average time.\"\"\"\n",
    "        return sum(self.times) / len(self.times)\n",
    "\n",
    "    def sum(self):\n",
    "        \"\"\"Return the sum of time.\"\"\"\n",
    "        return sum(self.times)\n",
    "\n",
    "    def cumsum(self):\n",
    "        \"\"\"Return the accumulated time.\"\"\"\n",
    "        return np.array(self.times).cumsum().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae8fff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, data_iter, lr, num_epochs):\n",
    "    def init_weights(module):\n",
    "        if type(module) == nn.Embedding:\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    net.apply(init_weights)\n",
    "    net = net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    animator = Animator(xlabel='epoch', ylabel='loss')\n",
    "    # Sum of normalized losses, no. of normalized losses\n",
    "    metric = Accumulator(2)\n",
    "    for epoch in range(num_epochs):\n",
    "        timer, num_batches = Timer(), len(data_iter)\n",
    "        for i, batch in enumerate(data_iter):\n",
    "            optimizer.zero_grad()\n",
    "            center, context_negative, mask, label = [\n",
    "                data.to(device) for data in batch]\n",
    "\n",
    "            pred = skip_gram(center, context_negative, net[0], net[1])\n",
    "            l = (loss(pred.reshape(label.shape).float(), label.float(), mask)\n",
    "                     / mask.sum(axis=1) * mask.shape[1])\n",
    "            l.sum().backward()\n",
    "            optimizer.step()\n",
    "            metric.add(l.sum(), l.numel())\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,\n",
    "                             (metric[0] / metric[1],))\n",
    "    Animator.show()\n",
    "    print(f'loss {metric[0] / metric[1]:.3f}, '\n",
    "          f'{metric[1] / timer.stop():.1f} tokens/sec on {str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b7cb513",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m lr, num_epochs = \u001b[32m0.002\u001b[39m, \u001b[32m5\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(net, data_iter, lr, num_epochs)\u001b[39m\n\u001b[32m     24\u001b[39m         metric.add(l.sum(), l.numel())\n\u001b[32m     25\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (i + \u001b[32m1\u001b[39m) % (num_batches // \u001b[32m5\u001b[39m) == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m i == num_batches - \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m             \u001b[43manimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m                         \u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m Animator.show()\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mloss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric[\u001b[32m0\u001b[39m]\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39mmetric[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     30\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric[\u001b[32m1\u001b[39m]\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39mtimer.stop()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m tokens/sec on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mAnimator.add\u001b[39m\u001b[34m(self, epoch, metrics)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd\u001b[39m(\u001b[38;5;28mself\u001b[39m, epoch, metrics):\n\u001b[32m      7\u001b[39m \t\u001b[38;5;28mself\u001b[39m.epochs.append(epoch)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \ttrain_loss, train_acc, test_acc = metrics\n\u001b[32m      9\u001b[39m \t\u001b[38;5;28;01mif\u001b[39;00m train_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     10\u001b[39m \t\t\u001b[38;5;28mself\u001b[39m.data[\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m].append(\u001b[38;5;28mfloat\u001b[39m(train_loss))\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 3, got 1)"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.002, 5\n",
    "train(net, data_iter, lr, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
