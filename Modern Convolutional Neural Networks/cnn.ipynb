{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fb1e828",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f883adff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 5070\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "from torch.nn import functional as F\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef089c80",
   "metadata": {},
   "source": [
    "# Deep Convolutional Neural Networks (AlexNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24d45ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNIST:\n",
    "    \"\"\"The Fashion-MNIST dataset.\"\"\"\n",
    "    def __init__(self, batch_size=64, resize=(28, 28)):\n",
    "        trans = transforms.Compose([transforms.Resize(resize),\n",
    "                                    transforms.ToTensor()])\n",
    "        self.root = \"/\"\n",
    "        self.batch_size = batch_size\n",
    "        self.train = torchvision.datasets.FashionMNIST(\n",
    "            root=self.root, train=True, transform=trans, download=True)\n",
    "        self.val = torchvision.datasets.FashionMNIST(\n",
    "            root=self.root, train=False, transform=trans, download=True)\n",
    "\n",
    "    def text_labels(self, indices):\n",
    "        \"\"\"Return text labels.\"\"\"\n",
    "        labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "                'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "        return [labels[int(i)] for i in indices]\n",
    "\n",
    "    def get_dataloader(self, train):\n",
    "        data = self.train if train else self.val\n",
    "        return torch.utils.data.DataLoader(data, self.batch_size, shuffle=train)\n",
    "    \n",
    "    def visualize(self, batch, nrows=1, ncols=8, labels=[]):\n",
    "        X, y = batch\n",
    "        if not labels:\n",
    "            labels = self.text_labels(y)\n",
    "        plt.figure(figsize=(2 * ncols, 2 * nrows))\n",
    "        max_imgs = min(X.shape[0], nrows * ncols)\n",
    "        for i in range(max_imgs):\n",
    "            plt.subplot(nrows, ncols, i + 1)\n",
    "            img = X[i].squeeze().numpy()\n",
    "            plt.imshow(img, cmap='gray')\n",
    "            plt.title(labels[i])\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "860cd492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cnn(module): \n",
    "    \"\"\"Initialize weights for CNNs.\"\"\"\n",
    "    if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, lr=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(96, kernel_size=11, stride=4, padding=1),\n",
    "            nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.LazyConv2d(256, kernel_size=5, padding=2), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.LazyConv2d(384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.LazyConv2d(384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.LazyConv2d(256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), nn.Flatten(),\n",
    "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(p=0.5),\n",
    "            nn.LazyLinear(4096), nn.ReLU(),nn.Dropout(p=0.5),\n",
    "            nn.LazyLinear(num_classes))\n",
    "        self.net.apply(init_cnn)\n",
    "\n",
    "    def layer_summary(self, X_shape):\n",
    "        X = torch.randn(*X_shape)\n",
    "        for layer in self.net:\n",
    "            X = layer(X)\n",
    "            print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "    \n",
    "    def fit(self, train_loader, num_epochs=10, lr=0.1):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        self.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss, total_correct, total_samples = 0, 0, 0\n",
    "            for X, y in train_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(X)\n",
    "                loss = criterion(outputs, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item() * X.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total_correct += (predicted == y).sum().item()\n",
    "                total_samples += y.size(0)\n",
    "            avg_loss = total_loss / total_samples\n",
    "            accuracy = total_correct / total_samples\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f46c06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape:\t torch.Size([1, 96, 54, 54])\n",
      "ReLU output shape:\t torch.Size([1, 96, 54, 54])\n",
      "MaxPool2d output shape:\t torch.Size([1, 96, 26, 26])\n",
      "Conv2d output shape:\t torch.Size([1, 256, 26, 26])\n",
      "ReLU output shape:\t torch.Size([1, 256, 26, 26])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 384, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 384, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 384, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 384, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 256, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 256, 12, 12])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 5, 5])\n",
      "Flatten output shape:\t torch.Size([1, 6400])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "AlexNet().layer_summary((1, 1, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805524b",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7936009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = FashionMNIST(batch_size=128, resize=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7833fac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8266cc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 188537954235.4920, Accuracy: 0.1007\n",
      "Epoch 2/10, Loss: 2.3165, Accuracy: 0.0992\n",
      "Epoch 3/10, Loss: 2.3146, Accuracy: 0.0993\n",
      "Epoch 4/10, Loss: 2.3091, Accuracy: 0.1010\n",
      "Epoch 5/10, Loss: 2.3089, Accuracy: 0.1011\n",
      "Epoch 6/10, Loss: 2.3088, Accuracy: 0.0993\n",
      "Epoch 7/10, Loss: 2.3079, Accuracy: 0.0998\n",
      "Epoch 8/10, Loss: 2.3088, Accuracy: 0.0992\n",
      "Epoch 9/10, Loss: 2.3089, Accuracy: 0.0998\n",
      "Epoch 10/10, Loss: 2.3089, Accuracy: 0.1007\n"
     ]
    }
   ],
   "source": [
    "model.fit(data.get_dataloader(train=True), num_epochs=10, lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7398c2",
   "metadata": {},
   "source": [
    "# Networks Using Blocks (VGG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f6ad41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(num_convs, out_channels):\n",
    "    layers = []\n",
    "    for _ in range(num_convs):\n",
    "        layers.append(nn.LazyConv2d(out_channels, kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91d3fa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, arch, lr=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        conv_blks = []\n",
    "        for (num_convs, out_channels) in arch:\n",
    "            conv_blks.append(vgg_block(num_convs, out_channels))\n",
    "        self.net = nn.Sequential(\n",
    "            *conv_blks, nn.Flatten(),\n",
    "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.LazyLinear(num_classes))\n",
    "        self.net.apply(init_cnn)\n",
    "    \n",
    "    def layer_summary(self, X_shape):\n",
    "        X = torch.randn(*X_shape)\n",
    "        for layer in self.net:\n",
    "            X = layer(X)\n",
    "            print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "\n",
    "    def fit(self, train_loader, num_epochs=10, lr=0.1):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        self.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss, total_correct, total_samples = 0, 0, 0\n",
    "            for X, y in train_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(X)\n",
    "                loss = criterion(outputs, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item() * X.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total_correct += (predicted == y).sum().item()\n",
    "                total_samples += y.size(0)\n",
    "            avg_loss = total_loss / total_samples\n",
    "            accuracy = total_correct / total_samples\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d51786e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 112, 112])\n",
      "Sequential output shape:\t torch.Size([1, 128, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 256, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 512, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
      "Flatten output shape:\t torch.Size([1, 25088])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "VGG(arch=((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))).layer_summary(\n",
    "    (1, 1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99ef7329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 13716171127.3777, Accuracy: 0.1007\n",
      "Epoch 2/10, Loss: 5.7668, Accuracy: 0.0990\n",
      "Epoch 3/10, Loss: 4.5712, Accuracy: 0.0989\n",
      "Epoch 4/10, Loss: 5.8548, Accuracy: 0.0993\n",
      "Epoch 5/10, Loss: 2.8603, Accuracy: 0.1019\n",
      "Epoch 6/10, Loss: 2.4818, Accuracy: 0.0995\n",
      "Epoch 7/10, Loss: 2.5361, Accuracy: 0.1001\n",
      "Epoch 8/10, Loss: 2.9694, Accuracy: 0.0999\n",
      "Epoch 9/10, Loss: 2.6205, Accuracy: 0.0983\n",
      "Epoch 10/10, Loss: 6.4324, Accuracy: 0.0999\n"
     ]
    }
   ],
   "source": [
    "model = VGG(arch=((1, 16), (1, 32), (2, 64), (2, 128), (2, 128)), lr=0.01)\n",
    "data = FashionMNIST(batch_size=128, resize=(224, 224))\n",
    "model.fit(data.get_dataloader(train=True), num_epochs=10, lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bb4160",
   "metadata": {},
   "source": [
    "# Network in Network (NiN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8deba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nin_block(out_channels, kernel_size, strides, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.LazyConv2d(out_channels, kernel_size, strides, padding), nn.ReLU(),\n",
    "        nn.LazyConv2d(out_channels, kernel_size=1), nn.ReLU(),\n",
    "        nn.LazyConv2d(out_channels, kernel_size=1), nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15996bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NiN(nn.Module):\n",
    "    def __init__(self, lr=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.net = nn.Sequential(\n",
    "            nin_block(96, kernel_size=11, strides=4, padding=0),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nin_block(256, kernel_size=5, strides=1, padding=2),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nin_block(384, kernel_size=3, strides=1, padding=1),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nn.Dropout(0.5),\n",
    "            nin_block(num_classes, kernel_size=3, strides=1, padding=1),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten())\n",
    "        self.net.apply(init_cnn)\n",
    "    \n",
    "    def layer_summary(self, X_shape):\n",
    "        X = torch.randn(*X_shape)\n",
    "        for layer in self.net:\n",
    "            X = layer(X)\n",
    "            print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "\n",
    "    def fit(self, train_loader, num_epochs=10, lr=0.01):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        self.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss, total_correct, total_samples = 0, 0, 0\n",
    "            for X, y in train_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(X)\n",
    "                loss = criterion(outputs, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item() * X.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total_correct += (predicted == y).sum().item()\n",
    "                total_samples += y.size(0)\n",
    "            avg_loss = total_loss / total_samples\n",
    "            accuracy = total_correct / total_samples\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1015b490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 96, 54, 54])\n",
      "MaxPool2d output shape:\t torch.Size([1, 96, 26, 26])\n",
      "Sequential output shape:\t torch.Size([1, 256, 26, 26])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 12, 12])\n",
      "Sequential output shape:\t torch.Size([1, 384, 12, 12])\n",
      "MaxPool2d output shape:\t torch.Size([1, 384, 5, 5])\n",
      "Dropout output shape:\t torch.Size([1, 384, 5, 5])\n",
      "Sequential output shape:\t torch.Size([1, 10, 5, 5])\n",
      "AdaptiveAvgPool2d output shape:\t torch.Size([1, 10, 1, 1])\n",
      "Flatten output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "NiN().layer_summary((1, 1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa7ec06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 2.3068, Accuracy: 0.0993\n",
      "Epoch 2/10, Loss: 2.3026, Accuracy: 0.1000\n",
      "Epoch 3/10, Loss: 2.3026, Accuracy: 0.1000\n",
      "Epoch 4/10, Loss: 2.3026, Accuracy: 0.1000\n",
      "Epoch 5/10, Loss: 2.3026, Accuracy: 0.1000\n",
      "Epoch 6/10, Loss: 2.3026, Accuracy: 0.1000\n",
      "Epoch 7/10, Loss: 2.3026, Accuracy: 0.1000\n",
      "Epoch 8/10, Loss: 2.3026, Accuracy: 0.1000\n",
      "Epoch 9/10, Loss: 2.3026, Accuracy: 0.1000\n",
      "Epoch 10/10, Loss: 2.3026, Accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "model = NiN(lr=0.05)\n",
    "data = FashionMNIST(batch_size=128, resize=(224, 224))\n",
    "model.fit(data.get_dataloader(train=True), num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781deedf",
   "metadata": {},
   "source": [
    "# Mutli-Branch Networks (GoogLeNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3b9fd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    # c1--c4 are the number of output channels for each branch\n",
    "    def __init__(self, c1, c2, c3, c4, **kwargs):\n",
    "        super(Inception, self).__init__(**kwargs)\n",
    "        # Branch 1\n",
    "        self.b1_1 = nn.LazyConv2d(c1, kernel_size=1)\n",
    "        # Branch 2\n",
    "        self.b2_1 = nn.LazyConv2d(c2[0], kernel_size=1)\n",
    "        self.b2_2 = nn.LazyConv2d(c2[1], kernel_size=3, padding=1)\n",
    "        # Branch 3\n",
    "        self.b3_1 = nn.LazyConv2d(c3[0], kernel_size=1)\n",
    "        self.b3_2 = nn.LazyConv2d(c3[1], kernel_size=5, padding=2)\n",
    "        # Branch 4\n",
    "        self.b4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.b4_2 = nn.LazyConv2d(c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b1 = F.relu(self.b1_1(x))\n",
    "        b2 = F.relu(self.b2_2(F.relu(self.b2_1(x))))\n",
    "        b3 = F.relu(self.b3_2(F.relu(self.b3_1(x))))\n",
    "        b4 = F.relu(self.b4_2(self.b4_1(x)))\n",
    "        return torch.cat((b1, b2, b3, b4), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52325041",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleNet(nn.Module):\n",
    "    def b1(self):\n",
    "        return nn.Sequential(\n",
    "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    def b2(self):\n",
    "        return nn.Sequential(\n",
    "            nn.LazyConv2d(64, kernel_size=1), nn.ReLU(),\n",
    "            nn.LazyConv2d(192, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    def b3(self):\n",
    "        return nn.Sequential(Inception(64, (96, 128), (16, 32), 32),\n",
    "                            Inception(128, (128, 192), (32, 96), 64),\n",
    "                            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    def b4(self):\n",
    "        return nn.Sequential(Inception(192, (96, 208), (16, 48), 64),\n",
    "                            Inception(160, (112, 224), (24, 64), 64),\n",
    "                            Inception(128, (128, 256), (24, 64), 64),\n",
    "                            Inception(112, (144, 288), (32, 64), 64),\n",
    "                            Inception(256, (160, 320), (32, 128), 128),\n",
    "                            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    def b5(self):\n",
    "        return nn.Sequential(Inception(256, (160, 320), (32, 128), 128),\n",
    "                            Inception(384, (192, 384), (48, 128), 128),\n",
    "                            nn.AdaptiveAvgPool2d((1,1)), nn.Flatten())\n",
    "    \n",
    "    def __init__(self, lr=0.1, num_classes=10):\n",
    "        super(GoogleNet, self).__init__()\n",
    "        self.lr = lr\n",
    "        self.net = nn.Sequential(self.b1(), self.b2(), self.b3(), self.b4(),\n",
    "                                self.b5(), nn.LazyLinear(num_classes))\n",
    "        self.net.apply(init_cnn)\n",
    "\n",
    "    def layer_summary(self, X_shape):\n",
    "        X = torch.randn(*X_shape)\n",
    "        for layer in self.net:\n",
    "            X = layer(X)\n",
    "            print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "\n",
    "    def fit(self, train_loader, num_epochs=10, lr=0.01):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        self.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss, total_correct, total_samples = 0, 0, 0\n",
    "            for X, y in train_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(X)\n",
    "                loss = criterion(outputs, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item() * X.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total_correct += (predicted == y).sum().item()\n",
    "                total_samples += y.size(0)\n",
    "            avg_loss = total_loss / total_samples\n",
    "            accuracy = total_correct / total_samples\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e3dc241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 2.7859, Accuracy: 0.0992\n",
      "Epoch 2/10, Loss: 2.3033, Accuracy: 0.0999\n",
      "Epoch 3/10, Loss: 2.3032, Accuracy: 0.0982\n",
      "Epoch 4/10, Loss: 2.3033, Accuracy: 0.0979\n",
      "Epoch 5/10, Loss: 2.3032, Accuracy: 0.0988\n",
      "Epoch 6/10, Loss: 2.3033, Accuracy: 0.0999\n",
      "Epoch 7/10, Loss: 2.3034, Accuracy: 0.0994\n",
      "Epoch 8/10, Loss: 2.3033, Accuracy: 0.1009\n",
      "Epoch 9/10, Loss: 2.3033, Accuracy: 0.0993\n",
      "Epoch 10/10, Loss: 2.3034, Accuracy: 0.0977\n"
     ]
    }
   ],
   "source": [
    "model = GoogleNet(lr=0.01)\n",
    "data = FashionMNIST(batch_size=128, resize=(96, 96))\n",
    "model.fit(data.get_dataloader(train=True), num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c5d2eb",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a89aaa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
    "    # Use is_grad_enabled to determine whether we are in training mode\n",
    "    if not torch.is_grad_enabled():\n",
    "        # In prediction mode, use mean and variance obtained by moving average\n",
    "        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
    "    else:\n",
    "        assert len(X.shape) in (2, 4)\n",
    "        if len(X.shape) == 2:\n",
    "            # When using a fully connected layer, calculate the mean and\n",
    "            # variance on the feature dimension\n",
    "            mean = X.mean(dim=0)\n",
    "            var = ((X - mean) ** 2).mean(dim=0)\n",
    "        else:\n",
    "            # When using a two-dimensional convolutional layer, calculate the\n",
    "            # mean and variance on the channel dimension (axis=1). Here we\n",
    "            # need to maintain the shape of X, so that the broadcasting\n",
    "            # operation can be carried out later\n",
    "            mean = X.mean(dim=(0, 2, 3), keepdim=True)\n",
    "            var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)\n",
    "        # In training mode, the current mean and variance are used\n",
    "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
    "        # Update the mean and variance using moving average\n",
    "        moving_mean = (1.0 - momentum) * moving_mean + momentum * mean\n",
    "        moving_var = (1.0 - momentum) * moving_var + momentum * var\n",
    "    Y = gamma * X_hat + beta  # Scale and shift\n",
    "    return Y, moving_mean.data, moving_var.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab8224ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    # num_features: the number of outputs for a fully connected layer or the\n",
    "    # number of output channels for a convolutional layer. num_dims: 2 for a\n",
    "    # fully connected layer and 4 for a convolutional layer\n",
    "    def __init__(self, num_features, num_dims):\n",
    "        super().__init__()\n",
    "        if num_dims == 2:\n",
    "            shape = (1, num_features)\n",
    "        else:\n",
    "            shape = (1, num_features, 1, 1)\n",
    "        # The scale parameter and the shift parameter (model parameters) are\n",
    "        # initialized to 1 and 0, respectively\n",
    "        self.gamma = nn.Parameter(torch.ones(shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(shape))\n",
    "        # The variables that are not model parameters are initialized to 0 and\n",
    "        # 1\n",
    "        self.moving_mean = torch.zeros(shape)\n",
    "        self.moving_var = torch.ones(shape)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # If X is not on the main memory, copy moving_mean and moving_var to\n",
    "        # the device where X is located\n",
    "        if self.moving_mean.device != X.device:\n",
    "            self.moving_mean = self.moving_mean.to(X.device)\n",
    "            self.moving_var = self.moving_var.to(X.device)\n",
    "        # Save the updated moving_mean and moving_var\n",
    "        Y, self.moving_mean, self.moving_var = batch_norm(\n",
    "            X, self.gamma, self.beta, self.moving_mean,\n",
    "            self.moving_var, eps=1e-5, momentum=0.1)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "357970d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNLeNetScratch(nn.Module):\n",
    "    def __init__(self, lr=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(6, kernel_size=5), nn.LazyBatchNorm2d(),\n",
    "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.LazyConv2d(16, kernel_size=5), nn.LazyBatchNorm2d(),\n",
    "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(), nn.LazyLinear(120), nn.LazyBatchNorm1d(),\n",
    "            nn.Sigmoid(), nn.LazyLinear(84), nn.LazyBatchNorm1d(),\n",
    "            nn.Sigmoid(), nn.LazyLinear(num_classes))\n",
    "    \n",
    "    def layer_summary(self, X_shape):\n",
    "        X = torch.randn(*X_shape)\n",
    "        for layer in self.net:\n",
    "            X = layer(X)\n",
    "            print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "\n",
    "    def fit(self, train_loader, num_epochs=10, lr=0.01):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        self.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss, total_correct, total_samples = 0, 0, 0\n",
    "            for X, y in train_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(X)\n",
    "                loss = criterion(outputs, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item() * X.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total_correct += (predicted == y).sum().item()\n",
    "                total_samples += y.size(0)\n",
    "            avg_loss = total_loss / total_samples\n",
    "            accuracy = total_correct / total_samples\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad8db8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.5644, Accuracy: 0.8024\n",
      "Epoch 2/10, Loss: 0.3686, Accuracy: 0.8646\n",
      "Epoch 3/10, Loss: 0.3181, Accuracy: 0.8826\n",
      "Epoch 4/10, Loss: 0.2886, Accuracy: 0.8932\n",
      "Epoch 5/10, Loss: 0.2717, Accuracy: 0.8997\n",
      "Epoch 6/10, Loss: 0.2523, Accuracy: 0.9067\n",
      "Epoch 7/10, Loss: 0.2393, Accuracy: 0.9107\n",
      "Epoch 8/10, Loss: 0.2293, Accuracy: 0.9139\n",
      "Epoch 9/10, Loss: 0.2149, Accuracy: 0.9195\n",
      "Epoch 10/10, Loss: 0.2096, Accuracy: 0.9215\n"
     ]
    }
   ],
   "source": [
    "model = BNLeNetScratch(lr=0.1)\n",
    "data = FashionMNIST(batch_size=128)\n",
    "model.fit(data.get_dataloader(train=True), num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2f9839",
   "metadata": {},
   "source": [
    "# Residual Networks (ResNet) and ResNeXt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5ad38b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    \"\"\"The Residual block of ResNet models.\"\"\"\n",
    "    def __init__(self, num_channels, use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1,\n",
    "                                   stride=strides)\n",
    "        self.conv2 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1,\n",
    "                                       stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.LazyBatchNorm2d()\n",
    "        self.bn2 = nn.LazyBatchNorm2d()\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return F.relu(Y)\n",
    "    \n",
    "    def fit(self, train_loader, num_epochs=10, lr=0.01):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        self.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss, total_correct, total_samples = 0, 0, 0\n",
    "            for X, y in train_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(X)\n",
    "                loss = criterion(outputs, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item() * X.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total_correct += (predicted == y).sum().item()\n",
    "                total_samples += y.size(0)\n",
    "            avg_loss = total_loss / total_samples\n",
    "            accuracy = total_correct / total_samples\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fc65849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 6, 6])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = Residual(3)\n",
    "X = torch.randn(4, 3, 6, 6)\n",
    "blk(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07f53c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 3, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = Residual(6, use_1x1conv=True, strides=2)\n",
    "blk(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1bbced",
   "metadata": {},
   "source": [
    "## ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29fb96f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def b1(self):\n",
    "        return nn.Sequential(\n",
    "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    def block(self, num_residuals, num_channels, first_block=False):\n",
    "        blk = []\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                blk.append(Residual(num_channels, use_1x1conv=True, strides=2))\n",
    "            else:\n",
    "                blk.append(Residual(num_channels))\n",
    "        return nn.Sequential(*blk)\n",
    "    \n",
    "    def __init__(self, arch, lr=0.1, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.net = nn.Sequential(self.b1())\n",
    "        for i, b in enumerate(arch):\n",
    "            self.net.add_module(f'b{i+2}', self.block(*b, first_block=(i==0)))\n",
    "        self.net.add_module('last', nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
    "            nn.LazyLinear(num_classes)))\n",
    "        self.net.apply(init_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcf94f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(ResNet):\n",
    "    def __init__(self, lr=0.1, num_classes=10):\n",
    "        super().__init__(((2, 64), (2, 128), (2, 256), (2, 512)),\n",
    "                       lr, num_classes)\n",
    "    def layer_summary(self, X_shape):\n",
    "        X = torch.randn(*X_shape)\n",
    "        for layer in self.net:\n",
    "            X = layer(X)\n",
    "            print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "\n",
    "    def fit(self, train_loader, num_epochs=10, lr=0.01):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        self.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss, total_correct, total_samples = 0, 0, 0\n",
    "            for X, y in train_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(X)\n",
    "                loss = criterion(outputs, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item() * X.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total_correct += (predicted == y).sum().item()\n",
    "                total_samples += y.size(0)\n",
    "            avg_loss = total_loss / total_samples\n",
    "            accuracy = total_correct / total_samples\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f35c8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 24, 24])\n",
      "Sequential output shape:\t torch.Size([1, 64, 24, 24])\n",
      "Sequential output shape:\t torch.Size([1, 128, 12, 12])\n",
      "Sequential output shape:\t torch.Size([1, 256, 6, 6])\n",
      "Sequential output shape:\t torch.Size([1, 512, 3, 3])\n",
      "Sequential output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "ResNet18().layer_summary((1, 1, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72bc2251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6537, Accuracy: 0.7676\n",
      "Epoch 2/10, Loss: 0.3332, Accuracy: 0.8782\n",
      "Epoch 3/10, Loss: 0.2849, Accuracy: 0.8967\n",
      "Epoch 4/10, Loss: 0.2553, Accuracy: 0.9063\n",
      "Epoch 5/10, Loss: 0.2331, Accuracy: 0.9139\n",
      "Epoch 6/10, Loss: 0.2190, Accuracy: 0.9190\n",
      "Epoch 7/10, Loss: 0.2031, Accuracy: 0.9254\n",
      "Epoch 8/10, Loss: 0.1900, Accuracy: 0.9301\n",
      "Epoch 9/10, Loss: 0.1766, Accuracy: 0.9348\n",
      "Epoch 10/10, Loss: 0.1647, Accuracy: 0.9384\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18(lr=0.01)\n",
    "data = FashionMNIST(batch_size=128, resize=(96, 96))\n",
    "model.fit(data.get_dataloader(train=True), num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fead660e",
   "metadata": {},
   "source": [
    "# ResNeXt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62b333a",
   "metadata": {},
   "source": [
    "## ResNeXt Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db6a27b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNeXtBlock(nn.Module):\n",
    "    \"\"\"The ResNeXt block.\"\"\"\n",
    "    def __init__(self, num_channels, groups, bot_mul, use_1x1conv=False,\n",
    "                 strides=1):\n",
    "        super().__init__()\n",
    "        bot_channels = int(round(num_channels * bot_mul))\n",
    "        self.conv1 = nn.LazyConv2d(bot_channels, kernel_size=1, stride=1)\n",
    "        self.conv2 = nn.LazyConv2d(bot_channels, kernel_size=3,\n",
    "                                   stride=strides, padding=1,\n",
    "                                   groups=bot_channels//groups)\n",
    "        self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1, stride=1)\n",
    "        self.bn1 = nn.LazyBatchNorm2d()\n",
    "        self.bn2 = nn.LazyBatchNorm2d()\n",
    "        self.bn3 = nn.LazyBatchNorm2d()\n",
    "        if use_1x1conv:\n",
    "            self.conv4 = nn.LazyConv2d(num_channels, kernel_size=1,\n",
    "                                       stride=strides)\n",
    "            self.bn4 = nn.LazyBatchNorm2d()\n",
    "        else:\n",
    "            self.conv4 = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = F.relu(self.bn2(self.conv2(Y)))\n",
    "        Y = self.bn3(self.conv3(Y))\n",
    "        if self.conv4:\n",
    "            X = self.bn4(self.conv4(X))\n",
    "        return F.relu(Y + X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89c36697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 96, 96])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = ResNeXtBlock(32, 16, 1)\n",
    "X = torch.randn(4, 32, 96, 96)\n",
    "blk(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dcd5ce",
   "metadata": {},
   "source": [
    "# DenseNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4e1b30",
   "metadata": {},
   "source": [
    "## Dense Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3b5fa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(num_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.LazyBatchNorm2d(), nn.ReLU(),\n",
    "        nn.LazyConv2d(num_channels, kernel_size=3, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d101f922",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, num_convs, num_channels):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        layer = []\n",
    "        for i in range(num_convs):\n",
    "            layer.append(conv_block(num_channels))\n",
    "        self.net = nn.Sequential(*layer)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for blk in self.net:\n",
    "            Y = blk(X)\n",
    "            # Concatenate input and output of each block along the channels\n",
    "            X = torch.cat((X, Y), dim=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c566b0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 23, 8, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = DenseBlock(2, 10)\n",
    "X = torch.randn(4, 3, 8, 8)\n",
    "Y = blk(X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7f0b8f",
   "metadata": {},
   "source": [
    "Here, we have 3 + 10 + 10 = 23 channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428d46be",
   "metadata": {},
   "source": [
    "## Transition Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2034dc",
   "metadata": {},
   "source": [
    "Reduces the number of channels using 1x1 convolution as well as halves the height and width using Average Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b575e613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_block(num_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.LazyBatchNorm2d(), nn.ReLU(),\n",
    "        nn.LazyConv2d(num_channels, kernel_size=1),\n",
    "        nn.AvgPool2d(kernel_size=2, stride=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d14b397e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 4, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = transition_block(10)\n",
    "blk(Y).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96da6d6",
   "metadata": {},
   "source": [
    "## DenseNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c272cdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    def b1(self):\n",
    "        return nn.Sequential(\n",
    "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    def __init__(self, num_channels=64, growth_rate=32, arch=(4, 4, 4, 4),\n",
    "             lr=0.1, num_classes=10):\n",
    "        super(DenseNet, self).__init__()\n",
    "        self.net = nn.Sequential(self.b1())\n",
    "        for i, num_convs in enumerate(arch):\n",
    "            self.net.add_module(f'dense_blk{i+1}', DenseBlock(num_convs,\n",
    "                                                            growth_rate))\n",
    "            # The number of output channels in the previous dense block\n",
    "            num_channels += num_convs * growth_rate\n",
    "            # A transition layer that halves the number of channels is added\n",
    "            # between the dense blocks\n",
    "            if i != len(arch) - 1:\n",
    "                num_channels //= 2\n",
    "                self.net.add_module(f'tran_blk{i+1}', transition_block(\n",
    "                    num_channels))\n",
    "        self.net.add_module('last', nn.Sequential(\n",
    "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
    "            nn.LazyLinear(num_classes)))\n",
    "        self.net.apply(init_cnn)\n",
    "\n",
    "    def layer_summary(self, X_shape):\n",
    "        X = torch.randn(*X_shape)\n",
    "        for layer in self.net:\n",
    "            X = layer(X)\n",
    "            print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "    \n",
    "    def fit(self, train_loader, num_epochs=10, lr=0.01):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        self.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss, total_correct, total_samples = 0, 0, 0\n",
    "            for X, y in train_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(X)\n",
    "                loss = criterion(outputs, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item() * X.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total_correct += (predicted == y).sum().item()\n",
    "                total_samples += y.size(0)\n",
    "            avg_loss = total_loss / total_samples\n",
    "            accuracy = total_correct / total_samples\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2b6f847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.5010, Accuracy: 0.8156\n",
      "Epoch 2/10, Loss: 0.3058, Accuracy: 0.8866\n",
      "Epoch 3/10, Loss: 0.2526, Accuracy: 0.9067\n",
      "Epoch 4/10, Loss: 0.2245, Accuracy: 0.9174\n",
      "Epoch 5/10, Loss: 0.2048, Accuracy: 0.9244\n",
      "Epoch 6/10, Loss: 0.1908, Accuracy: 0.9292\n",
      "Epoch 7/10, Loss: 0.1779, Accuracy: 0.9339\n",
      "Epoch 8/10, Loss: 0.1651, Accuracy: 0.9377\n",
      "Epoch 9/10, Loss: 0.1578, Accuracy: 0.9420\n",
      "Epoch 10/10, Loss: 0.1457, Accuracy: 0.9444\n"
     ]
    }
   ],
   "source": [
    "model = DenseNet(lr=0.01)\n",
    "data = FashionMNIST(batch_size=128, resize=(96, 96))\n",
    "model.fit(data.get_dataloader(train=True), num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828f7ed0",
   "metadata": {},
   "source": [
    "# AnyNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45bbbd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnyNet(nn.Module):\n",
    "    def stem(self, num_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.LazyConv2d(num_channels, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LazyBatchNorm2d(), nn.ReLU())\n",
    "    \n",
    "    def stage(self, depth, num_channels, groups, bot_mul):\n",
    "        blk = []\n",
    "        for i in range(depth):\n",
    "            if i == 0:\n",
    "                blk.append(ResNeXtBlock(num_channels, groups, bot_mul,\n",
    "                    use_1x1conv=True, strides=2))\n",
    "            else:\n",
    "                blk.append(ResNeXtBlock(num_channels, groups, bot_mul))\n",
    "        return nn.Sequential(*blk)\n",
    "    \n",
    "    def __init__(self, arch, stem_channels, lr=0.1, num_classes=10):\n",
    "        super(AnyNet, self).__init__()\n",
    "        self.net = nn.Sequential(self.stem(stem_channels))\n",
    "        for i, s in enumerate(arch):\n",
    "            self.net.add_module(f'stage{i+1}', self.stage(*s))\n",
    "        self.net.add_module('head', nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
    "            nn.LazyLinear(num_classes)))\n",
    "        self.net.apply(init_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14897707",
   "metadata": {},
   "source": [
    "# RegNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58a521d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegNetX32(AnyNet):\n",
    "    def __init__(self, lr=0.1, num_classes=10):\n",
    "        stem_channels, groups, bot_mul = 32, 16, 1\n",
    "        depths, channels = (4, 6), (32, 80)\n",
    "        super().__init__(\n",
    "            ((depths[0], channels[0], groups, bot_mul),\n",
    "             (depths[1], channels[1], groups, bot_mul)),\n",
    "            stem_channels, lr, num_classes)\n",
    "    \n",
    "    def layer_summary(self, X_shape):\n",
    "        X = torch.randn(*X_shape)\n",
    "        for layer in self.net:\n",
    "            X = layer(X)\n",
    "            print(layer.__class__.__name__, 'output shape:\\t', X.shape) \n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)  \n",
    "    \n",
    "    def fit(self, train_loader, num_epochs=10, lr=0.01):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        self.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss, total_correct, total_samples = 0, 0, 0\n",
    "            for X, y in train_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(X)\n",
    "                loss = criterion(outputs, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item() * X.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total_correct += (predicted == y).sum().item()\n",
    "                total_samples += y.size(0)\n",
    "            avg_loss = total_loss / total_samples\n",
    "            accuracy = total_correct / total_samples\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cd2956a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 32, 48, 48])\n",
      "Sequential output shape:\t torch.Size([1, 32, 24, 24])\n",
      "Sequential output shape:\t torch.Size([1, 80, 12, 12])\n",
      "Sequential output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "RegNetX32().layer_summary((1, 1, 96, 96))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc0ac2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.5361, Accuracy: 0.8029\n",
      "Epoch 2/10, Loss: 0.3217, Accuracy: 0.8826\n",
      "Epoch 3/10, Loss: 0.2784, Accuracy: 0.8985\n",
      "Epoch 4/10, Loss: 0.2455, Accuracy: 0.9106\n",
      "Epoch 5/10, Loss: 0.2318, Accuracy: 0.9163\n",
      "Epoch 6/10, Loss: 0.2171, Accuracy: 0.9214\n",
      "Epoch 7/10, Loss: 0.2081, Accuracy: 0.9229\n",
      "Epoch 8/10, Loss: 0.1957, Accuracy: 0.9285\n",
      "Epoch 9/10, Loss: 0.1864, Accuracy: 0.9319\n",
      "Epoch 10/10, Loss: 0.1827, Accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "model = RegNetX32(lr=0.05)\n",
    "data = FashionMNIST(batch_size=128, resize=(96, 96))\n",
    "model.fit(data.get_dataloader(train=True), num_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
